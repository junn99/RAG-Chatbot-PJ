import streamlit as st
from utils import print_messages, StreamHandler
# from vectordb import load_or_create_vector_store

from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

from langchain_ollama import ChatOllama

# history chat
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

st.set_page_config(page_title="AI Trend Bot",page_icon="ğŸ’¬")
st.title("ğŸ’¬AI Trend Bot")

# ì…ë ¥í•œ ë©”ì„¸ì§€ë“¤ì„ ê¸°ë¡í•  í•„ìš”ê°€ ìˆìŒ -> session state = ìºì‹±ê¸°ëŠ¥
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì±„íŒ… ëŒ€íšŒê¸°ë¡ì„ ì €ì¥í•˜ëŠ” store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
if "store" not in st.session_state:
    st.session_state["store"] = dict()

with st.sidebar:
    session_id = st.text_input("Session ID", value="abc123")
    # ì„¸ì…˜ id? -> ì¹´í†¡ë‹¹ id -> ìƒˆë¡œìš´ ì±„íŒ…ìœ¼ë¡œ ìƒê°í•˜ë©´ ë ë“¯

    clear_button = st.button("ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”")
    if clear_button:
        st.session_state["messages"] = [] # ê·¸ëƒ¥ ì›¹ìƒì—ì„œ ì •ë¦¬
        # st.session_state["store"] = dict() # ì´ê±° í™œì„±í™”í•˜ë©´ ì•„ì˜ˆ ê¸°ë¡ê¹Œì§€ ì´ˆê¸°í™”
        st.experimental_rerun()

# ì´ì „ ëŒ€í™”ê¸°ë¡ì„ ì¶œë ¥í•´ì£¼ëŠ” ì½”ë“œ
# print_messages()

# ë°ì´í„° ë¡œë“œ ë° ë²¡í„°DB ì €ì¥
# db = load_or_create_vector_store()
# retriever
# retriever = db.as_retriever(search_kwargs={"k": 2})

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_ids: str)-> BaseChatMessageHistory:
    if session_ids not in st.session_state["store"]: # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
        # ìƒˆë¡œìš´ ChatNessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥
        st.session_state["store"][session_ids] = ChatMessageHistory()
    return st.session_state["store"][session_ids] # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜

# ì±„íŒ…ê¸°ëŠ¥
# "assistant" & "user" : ì±„íŒ… ì•„ì´ì½˜
user_input = st.chat_input("ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.") # ì§€ì‹œë¬¸
if user_input:
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(user_input)
    st.session_state["messages"].append(ChatMessage(role="user", content=user_input))

    # LLMì„ ì‚¬ìš©í•˜ì—¬ AIì˜ ë‹µë³€ ìƒì„±
    # í”„ëŒí”„íŠ¸ -> ëª¨ë¸ -> ì²´ì¸ + ì•„ì›ƒí’‹íŒŒì„œ -> ì¸ë³´í¬ = msgë¡œ ë“¤ì–´ê°€ë©´ ë¨

    # 1. ëª¨ë¸ ìƒì„± wiht ollama
    llm = ChatOllama(
    model="gemma2",
    temperature=0.5
    # other params...
)
    
    # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
    # ì§ì ‘ ë§Œë“¤ì–´ì•¼ ê²Ÿë„¤ -> hubì—ì„œ pullí•˜ëŠ” ê±´ ì•ˆë˜ê² ë‹¤.
    # ì—¬ê¸°ë‹¤ê°€ í•œêµ­ì–´ë¡œ ë‹µë³€ + í˜ë¥´ì†Œë‚˜ê¹Œì§€ í•´ì„œ ì¶”ê°€í•´ì•¼ í•  ë“¯.
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                "ì§ˆë¬¸ì— ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”."
            ),
            # ëŒ€í™” ê¸°ë¡ì„ ë³€ìˆ˜ë¡œ ì‚¬ìš©, historyê°€ MessageHistoryì˜ keyê°€ ë¨.
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}"), # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì…ë ¥ 
        ]
    )

    chain = prompt | llm # chainê±°ëŠ”ê²Œ ì¢€ ë¹¡ì„¸ë„¤ promptì— ë§ì¶°ì„œ ë¨¼ê°€ í•´ì•¼í•  ê²ƒ ê°™ì€ë° ì™€ìš°

    chain_with_memory = (
    RunnableWithMessageHistory( # RunnableWithMessageHistoryê°ì²´ ìƒì„±
        chain, # ì‹¤í–‰í•  Runnable ê°ì²´
        get_session_history, # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        input_messages_key="question", # ì‚¬ìš©ì ì§ˆë¬¸ì˜ í‚¤
        history_messages_key="history", # ê¸°ë¡ ë©”ì„¸ì§€ì˜ í‚¤
    )
)

    # response = chain.invoke({"question": user_input})
    response = chain_with_memory.invoke(
        {"question":user_input},
        # ì„¸ì…˜ IDì„¤ì •
        config = {"configurable":{"session_id":session_id}}
    )
    

    msg = response.content

    # AIì˜ ë‹µë³€
    with st.chat_message("assistant"):
        stream_hander = StreamHandler(st.empty())
        st.write(msg)
        st.session_state["messages"].append(ChatMessage(role="assistant", content=msg))